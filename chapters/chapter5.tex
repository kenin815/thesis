\label{ch5}
\section{簡介}
在前一章節，利用專注式機制學習較好的向量表示，成功將平均準確率大幅提升，然而產生的查詢詞向量跟語音文件向量，就算為相似發音的詞，如hand跟hands，他們的向量表示卻大不相同。在本章中，想引入語音詞向量（Audio
Word2vec）的概念，能夠使模型學到詞的相關性，且語音詞向量是非監督式的學習方法，跟動態時間規劃的方法一樣，想嘗試以非監督式的方法，也能夠有進步。在語音詞向量模型中，會有每段詞的語音序列，才能夠訓練並產生出語音詞向量。但是我們在語音文件的部分，並無法得知每個詞的段落，所以本章想嘗試將即使不切出一段詞的語音序列而是將整段語音文件去產生出語音詞向量，並藉由分類器依據查詢詞的語音詞向量跟語音文件的語音詞向量判斷語音文件是否出現查詢詞。

\section{語音詞向量}
語音詞向量的概念為詞向量（Word Vector）的延伸，詞向量又稱詞嵌入（Word
Embedding）能夠將詞轉成有意義的向量。原本詞的表示方法常用的為是1-of-N編
碼（1-of-N
Encoding），也就是產生一個維度$N$的向量，$N$為辭典的詞數目，每一維度對應到一個詞，一個詞向量只有在該詞所對應到的維度其值為$1$，其$N-1$個維度的值都是$0$。此種表示法有其缺點，首先，$N$的維度都在數萬至數十萬的量級，導致詞向量的維度非常大。再者，此種表示法將所有的詞是為獨立，即便為兩個同義詞（Synonym），他們的1-of-N編碼之間也毫無關聯。而詞嵌入表示能夠產生分佈式表示（Distributed
Representation），將詞由原本的$N$維降低為幾百維度，且每一維度不在只有$1$或$0$，而是一連續的實數。且將語意關係或句法結構的關係，用兩個向量之間的歐式距離（Euclidean
Distance）或餘弦相似度（Cosine
Similarity）之大小就能呈現出來，例如母親與父親的歐式距離跟國王與皇后的歐式距離是相差不遠的。
語音詞向量則是希望在給定語音輸入下，也能夠產生固定維度的分佈式表示。
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{images/ch5_seq2seq.png} 
\caption{語音詞向量模型圖}
\label{ch5_seq2seq}
\end{figure}
\label{ch5_seq2seq}

圖\ref{ch5_seq2seq}為語音詞向量的模型架構，基本概念仍為先前在\ref{seq2seq}章中提到的序列對序列的架構。編碼器會先將語音序列依據每個時間點$F_t$一一當作輸入，在看完整段序列後，產生一個維度固定的隱藏狀態。接著解碼器會將隱藏狀態當作初始狀態，一一產生出每個時間點的輸出$Y_t$。使其$Y_t$跟學習目標$F_t$要能夠完全相同，模型會嘗試降低$Y_t$跟$F_t$的方均根差（root-mean-square
error）。最後取其隱藏狀態當作語音序列的分佈式向量表示，即為語音詞向量。
\section{模型架構}
\subsection{模型簡介}
圖\ref{ch5_model}為本章的模型架構圖，遞迴類神經網路編碼器會將查詢詞序列$Q_1,Q_2,...Q_T$編碼產生$V_Q$，語音文件序列$D_1,D_2,...,D_N$編碼產生$V_D$。接著，遞迴類神經網路解碼器會將$V_Q$跟$V_D$還原成原本的語音序列$\hat{Q_1},\hat{Q_2},...\hat{Q_T}$、$\hat{D_1},\hat{D_2},...,\hat{D_N}$，希望使其跟原本的序列越相近。最後，依照查詢詞向量$V_Q$跟語音文件向量$V_D$的歐式距離的分數排序，計算出平均準確率。

圖\ref{ch5_model}上有分別畫出語音文件跟查詢詞的編碼器和解碼器，但如同第\ref{ch3}章，編碼器為同一組的遞迴類神經網路，負責將語音文件跟查詢詞編碼成向量，而解碼器是另一組遞迴類神經網路負責。
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{images/ch5_model.png} 
\caption{模型架構圖}
\label{ch5_model}
\end{figure}
\subsection{訓練方式}
此時因模型需要能夠還原成原本的語音序列，其損失函數為均方根差如式\ref{eq:ch5_RMSE}，使其編碼向量經過解碼器後的輸出跟其原始語音序列越相近。
\begin{equation}
\label{eq:ch5_RMSE}
L_{rmse} (\bold{x},\bold{y}) = \sum_{i=1}^{T}
RMSE(\bold{x}_i-\bold{y}_i) = \sum_{i=1}^{T} \sum_{j=1}^D \sqrt{(x_{ij}-y_{ij})^2}
\end{equation}
其中RMSE為方均根差，$\bold{x}$為輸入之語音序列，$\bold{y}$為模型還原之語音序列，$\bold{x}_i$為時間點$i$之聲學特徵，$\bold{y}_i$
為時間點$i$之模型還原聲學特徵，T為輸入序列長度，D為聲學特徵向量維度。最佳化演算法採用Adam演算法，採用二次正規化並給予權重0.001。

\section{實驗與分析}
\subsection{實驗設定與基準實驗}
\begin{itemize}
\item{實驗設定}

訓練語料為LIBRISPEECH 的英語語料，從train-clean-360
取出30,000個語音文件當作訓練語料。測試語料跟章節\ref{ch4}的設定相同，分成測試集$1$、測試集$2$、測試集$3$。然而此三種測試集對語音詞向量模型並無差異，因此時模型並未將查詢詞當作訓練語料訓練，所以並未先看過查詢詞的情況。
\item{基準實驗}

基準實驗仍為利用動態時間規劃得到的分數，在分別在測試集$1$得到0.6173的平均準確率，測試集$2$得到0.5778的平均準確率，測試集$3$得到0.5668的平均準確率。
\end{itemize}
\subsection{實驗結果與分析}
表\ref{table:ch5_a2v}為實驗之結果，在此章比較了不同層數的長短期記憶網路，而每層的記憶網路細胞個數為$128$個。從表中可以看出，利用語音詞向量的結果跟基準實驗差異不大，只有在層數較深的模型下，才略贏基準實驗。

動態時間規劃跟語音詞向量皆為非監督式的學習方法，所以都不需要利用到標記的資料，然而語音詞向量仍須有訓練語料才能夠學習，這是語音詞向量的劣勢。且本章並未將語音文件切成文字片段在進行訓練，而是以整段語音文件進行訓練，這表示產生出來的向量代表了整個語音文件，並不是表示單一個詞，而計算語音查詢詞跟語音文件之間的歐式距離，若語音文件出現跟查詢詞相似的詞但未出現查詢詞，此時利用歐式距離判別會產生出偏差，為此方法的一大缺失。但語音詞向量在此表現卻能跟基準實驗抗衡，是蠻令人驚奇。

\begin{table}[ht]
	 \centering
	 \caption{語音詞向量之實驗結果}
	 \label{table:ch5_a2v}
	 \begin{tabular}{|c|c|c|c|}
		 \hline
		 模型架構 & 測試集1 & 測試集2 & 測試集3 \\
		 \hline
		 基準實驗 & 0.6173 & 0.5778 & 0.5678\\
		 \hline
		 一層長短期記憶網路& 0.6040 & 0.5890 & 0.5793 \\
		 \hline
		 兩層長短期記憶網路& 0.6160 &0.6038 &0.5988\\
		 \hline
		 三層長短期記憶網路& {\color{red}0.6223} &0.6127 &0.6011\\
		 \hline
	   \end{tabular}
\end{table}






\section{本章總結}
此章中利用了語音詞向量的概念，將未切段的語音文件直接進行訓練語音詞向量的模型。將語音文件與語音查詢詞分別產生其語音詞向量，利用它們之歐式距離來判定是否出現查詢詞。語音詞向量為非監督式學習，跟基準實驗動態時間規劃相同，也能夠產生與基準實驗相抗衡的表現。
