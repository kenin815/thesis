\section{研究動機}
雖著網路跟電腦的普及，導致資訊大爆炸。網路上的資訊愈來愈豐富，使尋找我們自己所需的資料是一個大問題。因此，我們需要一套好的檢索系統
(Retrieval System) 幫助我們快速地瀏覽資訊，並從中找到有用的部分，在過去已有許多文字檢索系統與演算法被開發出來並應用於產業中，如 Google Search、Microsoft Bing Search、Yahoo
Search等。隨著錄影音設備的普及，語音文件量正蓬勃地增加當中，隨著線上影片、會議錄音、線上課程等網站的興起，語音資料量越來越多，因此如何在其中找到使用者感興趣的資料便成為重要的議題，即為語音數位內容檢索 (Spoken Content Retrieval)~\cite{chelba2008retrieval, lee2005spoken}。相較於文字資訊檢索，語音資訊檢索面臨到更多的挑戰，如辨識錯誤、辨識訓練資料不足等問題，使得此問題更形困難。

更由於行動裝置的出現，使用者可以不受地形時間限制，隨時取得資訊，促使許多網路公司一一推出了自家的用語音輸入來檢索文字資訊的系統，如 Google 公司推出的語音檢索功能即可讓使用者在手機或瀏覽器的介面上以語音輸入，由 Google 將其辨識成文字後再於 Google 的搜尋引擎上檢索資訊。 Apple 公司推出的個人語音助理 Siri，也讓使用者能以十分自然的方式對 Siri 說出想要查詢的查詢詞 (Query) ，由 Siri 辨識後在網路上檢索，並將檢索結果分門別類整理好後呈現給使用者看。如上述所說的這類檢索系統是用語音輸入的查詢詞去檢索大量的文字資訊，此方法稱為人聲檢索 (Voice Search)，和本論文所探討的語音數位內容檢索 (Spoken Content Retrieval) 完全不同。

本論文所探討的語音數位內容檢索，是指由於網路上有大量的多媒體文件，如線上影片、會議錄音、線上課程、電視連續劇、演講等，而使用者也有搜尋這些多媒體文件的需求，此類允許使用者用文字或聲音輸入查詢詞並搜尋語音數位內容 (Spoken Content) 的系統稱為語音數位內容檢索 (Spoken Content Retrieval)，如 TED (美國著名的演講網站) 會將網站上的演講內容轉寫 (Transcript) 成為文字，並允許使用者於網站上輸入文字檢索這些影片的文字稿。 Youtube 也會於離線時將其網站上的影片辨識成文字，但目前尚不支援直接輸入查詢詞檢索影片轉寫的方式，可以期待未來 Youtube 會開放這方面的功能。只是上述兩個例子仍要倚賴人工的轉寫，要完全只靠機器自動辨識仍不容易做到。這種語音數位內容檢索將是本論文主要的研究主軸。

語音資訊檢索系統的效能取決於其前端語音辨識系統的效能，只要可以發展出完美的語音辨識系統，能夠完全正確的把聲音轉寫為文字，那需要將文件資訊檢索的方式套用到語音辨識的文字輸出上就解決語音資訊檢索這個問題了。依此邏輯來看，與其研究語音檢索，不如去研究如何提升語音辨識的正確率，而當完美的語音辨識系統被創造出來，語音檢索這個問題也就沒什麼好研究的了。因此TRECSDR track~\cite{trec}在2000年的時候即宣稱語音檢索在廣播新聞上(BroadcastNews)是一個「已解決的問題」(solved problem)，而在當時廣播新聞的辨識正確率已經到達90\%以上，但在自發性(Spontaneous)語音上，語音辨識正確率往往不到50\%，進而增加了在自發性語音上檢索的難度~\cite{saraclar2004lattice,mamou2006spoken}，因為訓練語料的不足或不匹配、聲學和語言模型的能力限制， 短時間內語音辨識錯誤似乎是不可避免的， 辨識錯誤對語音檢索所帶來的傷害幾乎在這個領域的每一篇論文的導論都會提到， 用以彰顯語音檢索仍是個值得研究的問題， 然而卻沒有太多方法能真正突破語音辨識錯誤所帶來的限制。 本論文因此將語音辨識的部分移除，直接在語音訊號本身進行搜索，以類神經網路直接學習語音訊號的相似性，有別於傳統的聲學模型訓練強調辨識正確率的提升，本論文所提出的移除語音辨識，直接由語音訊號進行搜索提升語音檢索的效能。

本論文想要探討的主題將是針對語音數位內容之語意檢索 (Semantic Retrieval of Spoken Content)，是指系統在接受到口語形式或文字形式的查詢詞之後，儘可能回傳給使用者所有與查詢詞語意上相關的語音文件。由於傳統的語音數位內容之語意檢索系統主要的實作方法為先將語音文件辨識為文字檔後，對文字做檢索，但在辨識之中，會遇到如詞典外詞彙
(OOV)、辨識錯誤等情況，更甚者，許多語音中珍貴的資訊如韻律 (Prosody)、語速 (Speaking Rate)和語者特徵 (Speaker Characteristic)等在辨識後就消失了，十分地可惜。因此本論文試圖結合一套自動習得的聲學組型 (Automatically Discovered Acoustic Patterns) 至語音數位內容之語意檢索當中，以期改善傳統的檢索系統。

\section{研究方向}
本論文之研究方向為使用自動習得之聲學組型強化語音數位內容之語意檢索，主要包含以下幾點：

\begin{itemize}
\itemsep -2pt %reduce space between items
  \item  傳統的語意檢索系統是先將語音文件辨識為文字後，將輸入的文字查詢詞進行查詢詞擴展 (Query Expansion)，再用擴展後查詢詞對辨識後的文字進行檢索，但如此一來許多語音訊號中的珍貴的聲學資訊就消失了。因此本章中在文字的查詢詞擴展之外，再加入一套自動習得之聲學組型的查詢詞擴展，並結合兩套查詢詞擴展之結果回傳給使用者。

  \item  更進一步地，本論文希望能處理口語形式的查詢詞，可以用口語形式的查詢詞進行語音數位內容之語意檢索。另一方面，語意檢索通常需要自動語音辨識系統 (Automatically Speech Recognition) 將聲音辨識成文字，進而得到語意上的資訊，但自動語音辨識系統的訓練是很昂貴的，需要大量標注完善的語料才能訓練出很好的聲學與語言模型。因此本章中會將聲音辨識成聲學組型，並在聲學組型上進行查詢詞擴展，進而達到非監督式語音數位內容之語意檢索 (Unsupervised Semantic Retrieval of Spoken Content)。
  
  \item  由於聲學組型在訓練時是盡量將聲音很像之片段盡量分群 (Clustering) 在一起，但如此一來會使得同一個聲學組型中包含了大量同音但對應到不同字詞的聲學組型，會使得檢索系統的成效大幅下降。因此本章使用基於遞迴式類神經網路語言模型 (Recurrent Neural Network Language Model, RNNLM) 之詞表示法 (Word Representation) 將這些聲學組型按照句法 (Syntactics) 和語意 (Semantics) 進一步分群為不同的聲學組型，進而提升檢索系統之成效。
   
  \item  最後，由於近年來行動裝置與穿戴式裝置日漸流行，使用者也漸漸習慣於在行動裝置上用語音輸入並取得資訊，因此本論文基於 Google 眼鏡 ( Google Glass) 上推出了一套語音翻譯系統與語音數位內容檢索系統，讓使用者能夠隨時隨地用最方便的方法取得新資訊。

\end{itemize}

\section{章節安排}
本論文之章節安排如下：

\begin{itemize}
\itemsep -2pt %reduce space between items
  \item  第二章：介紹本論文相關背景知識。
  \item  第三章：介紹如何以聲學組型改善監督式語意檢索。
  \item  第四章：介紹如何以聲學組型實現非監督式語意檢索。
  \item  第五章：介紹如何以遞迴式類神經網路語言模型產生之詞向量改善第四章的非監督式語音文件檢索。
  \item  第六章：介紹如何將本論文之語音檢索系統與語音翻譯系統實作到 Google Glass 上。
  \item  第七章：本論文之結論與未來研究方向。
\end{itemize}

